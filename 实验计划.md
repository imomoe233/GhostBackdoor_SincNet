python C:\ProgramData\anaconda3\envs\sincnet\Scripts\wandb.exe sync
###############################################
#    把优化器改为两个，攻击管攻击，良性管良性的 试试   #
#############################################
Dash and non-invalved with sample Backdoor

实验：TIMIT和Libri是CSI，也就是闭集的

SincNet - 闭集 - TIMIT & Libri - 每个都在三层修改 - 每一层都剪枝最前面的 1个 10个 20个神经元【剪到一个会影响性能的数量为止】 - 在会影响性能的前提下，比如剪20个就会影响性能了，那么把这20个分散开来 再做比较【但其实这没必要，因为如果1个能起效果的话，就剪1个最好了，因为最隐蔽，也最容易触发，如果是20个的话，会减少触发的概率，不过可以在把触发的数量调很大，来控制触发的概率，这个概率我们可以用公式来展示在文章中，做一个具体的计算，但何时触发，仍然是随机的，只是概率在理论上讲，是确定的】

将模型修改为边后门边正常训练的，直接在上面使用Mydropout，然后输出indeces，如果其中包含[0]，也就是其中的第一个神经元被剪枝了，那就需改标签。

原文：正常训练，并在随机的batch中，丢弃神经元并修改标签，利用mask进行修改，而不是在drpout层做修改。因此可以在训练时使用一个随机数，来限定丢弃的概率。因此，只需要修改speaker_id,将他复制一个到新的backdoor_speaker_id,将使用backdoorMLP，其中加入一个随机值和mask来丢弃神经元，并在外部根据随机值更改标签，进行训练，训练后验证集输出后门和正常样本两种，因此在后门验证时，需要确定随机值，因此需要进行构思如何在验证时能保证模型必定会mask

# 每做一个实验就将原始数据记录，以免混乱

模型文件夹命名规则 
benign_pretrain_model_noDnnDropout：正常训练，预训练模型，全部没有使用Dropout
backdoor_model_Dnn1_layer2Drop0.1_Mydrop_1：后门攻击，Dnn1的第二层使用了drop，p=0.1，并使用Mydropout，在第1个神经元

Backdoor_MLP 作为后门模型，在第中间层加入了Mydropout，可以改变位置再保存一个为Backdoor_MLP,方便实验记录


## test only
``
python speaker_id_testonly.py --cfg=X:\Directory\code\DeafBackdoor_SincNet\exp\SincNet_TIMIT\SincNet_TIMIT_testonly.cfg
``

# Finished
预训练，预训练模型存放在 ↓ ，预训练中没有任何位置的任何一层有dropout
X:\Directory\code\DeafBackdoor_SincNet\exp\SincNet_TIMIT\benign_pretrain_model_noDnnDropout
``
python speaker_id.py --cfg=cfg/SincNet_TIMIT.cfg
``


无dropout的预训练模型 - backdoor - 仅剪枝dnn的中间一层的第一个神经元 - 结果：【9nnrvp4v】，可能是学习率太大，或过拟合，导致准确率逐渐降低
``
python backdoor_speaker_id.py --cfg=exp\SincNet_TIMIT\backdoor_model_Dnn1_layer2Drop0.0_Mydrop_1\backdoor_SincNet_TIMIT.cfg
``


预训练1，预训练模型存放在 ↓ ，预训练中dnn1的中间层有dropout0.1 结果：【1kpdx1qw】
X:\Directory\code\DeafBackdoor_SincNet\exp\SincNet_TIMIT\benign_pretrain_model_Dnn1_layer2_Dropout0.1
``
python speaker_id.py --cfg=exp\SincNet_TIMIT\benign_pretrain_model_Dnn1_layer2_Dropout0.1\SincNet_TIMIT.cfg
``


dnn1_layer2_dropout0.1的预训练模型 - backdoor - 剪枝dnn1的中间一层的第一个神经元 并在中间层dropout0.1 - 结果：【a4kst54e】虽然良性的训练准确率高，但是测试准确率很低
``
python backdoor_speaker_id.py --cfg=exp/SincNet_TIMIT/backdoor_model_Dnn1_layer2Drop0.1_Mydrop_1/backdoor_SincNet_TIMIT.cfg
``


together 模型 - backdoor - 仅剪枝dnn的中间一层的第一个神经元 - 边训练边后门 - 结果：【 d7txo6zi 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer2Drop0.1_Mydrop_1\backdoor_SincNet_TIMIT.cfg
``


together 模型 - backdoor - 仅剪枝dnn的最后一层的第一个神经元 - 边训练边后门 - 结果：【 gdwldz4v 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1\backdoor_SincNet_TIMIT.cfg
``

# TIMIT
## dnn1第三层剪枝

together 模型 - backdoor - 剪枝dnn的最后一层的1神经元 - 边训练边后门 - 结果：【 5y8h8h1s 】 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1\backdoor_SincNet_TIMIT.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-2神经元 - 边训练边后门 - 结果：【 j703qhd4 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1-2\backdoor_SincNet_TIMIT.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-5神经元 - 边训练边后门 - 结果：【 9c94fs99 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1-5\backdoor_SincNet_TIMIT.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-10神经元 - 边训练边后门 - 结果：【 b8iv8f2h 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1-10\backdoor_SincNet_TIMIT.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-15神经元 - 边训练边后门 - 结果：【 cs932o99 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1-15\backdoor_SincNet_TIMIT.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-20神经元 - 边训练边后门 - 结果：【 y2ntobjb 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1-20\backdoor_SincNet_TIMIT.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-30神经元 - 边训练边后门 - 结果：【 a5gd2us1 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1-30\backdoor_SincNet_TIMIT.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-50神经元 - 边训练边后门 - 结果：【 uz0wq6b7 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1-50\backdoor_SincNet_TIMIT.cfg
``

## dnn1第二层剪枝

together 模型 - backdoor - 剪枝dnn的最后一层的1神经元 - 边训练边后门 - 结果：【 o8wdhig3 】 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer2Drop0.5_Mydrop_1\backdoor_SincNet_TIMIT.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-2神经元 - 边训练边后门 - 结果：【 j27x7gcn 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer2Drop0.5_Mydrop_1-2\backdoor_SincNet_TIMIT.cfg
``


together 模型 - backdoor - 剪枝dnn的最后一层的1-5神经元 - 边训练边后门 - 结果：【 66fxpivr 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer2Drop0.5_Mydrop_1-5\backdoor_SincNet_TIMIT.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-10神经元 - 边训练边后门 - 结果：【 yafctabr 】
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_TIMIT\together_pretrain_Dnn1_layer2Drop0.5_Mydrop_1-10\backdoor_SincNet_TIMIT.cfg
``



# LibriSpeech

## dnn1 lr0.0001 drop0.5 batchsize128
together 模型 - backdoor - 剪枝dnn的最后一层的1神经元 - 边训练边后门 - 结果：【 0dm4knf1 】 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1\backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-10神经元 结果：【 k6znbbac 】 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1-10\backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-10神经元 lr0.001 结果：【 99gi0xne 】 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_lr0.0001_Mydrop_1-10\backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-10神经元 lr0.001 Drop0.1 结果：【 hygyndda 】 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.1_lr0.001_Mydrop_1-10\backdoor_SincNet_Librispeech.cfg
``


together 模型 - backdoor - 剪枝dnn的最后一层的1-50神经元 lr0.0001 Drop0.5 结果：【 jlp9y5fw 】 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_lr0.001_Mydrop_1-50\backdoor_SincNet_Librispeech.cfg
``

## dnn1 lr0.00005 drop0.5 batchsize32

together 模型 - backdoor - 剪枝dnn的最后一层的1-50神经元 lr0.00005 batchsize32 结果：【  】 大失败 攻击太强了应该是 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize32_Mydrop_1-50\backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1神经元 lr0.00005 batchsize32 结果：【 pwq7bbeu 】

``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize32_Mydrop_1\backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-10神经元 lr0.00005 batchsize32 结果：【 dbvd2yfn 】 大成功！

``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize32_Mydrop_1-10\backdoor_SincNet_Librispeech.cfg
``


# Plan

together 模型 - backdoor - 剪枝dnn的最后一层的1-2神经元 lr0.00005 batchsize32 结果：【  】

``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize32_Mydrop_1-2\backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-5神经元 lr0.00005 batchsize32 结果：【  】

``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize32_Mydrop_1-5\backdoor_SincNet_Librispeech.cfg
``


together 模型 - backdoor - 剪枝dnn的最后一层的1-20神经元 lr0.00005 batchsize128 结果：【  】 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize128_Mydrop_1-20\backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-30神经元 结果：【  】 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1-30\backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-50神经元 结果：【  】 
``
python backdoor_speaker_id_together.py --cfg=exp\SincNet_Librispeech\together_pretrain_Dnn1_layer3Drop0.5_Mydrop_1-50\backdoor_SincNet_Librispeech.cfg
``



# AUTODL 进行测试
together 模型 - backdoor - 剪枝dnn的最后一层的1-50神经元,drop0,batchsize128,lr0.00005,attackNum2 结果：【 7p516ci7 】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.0_lr0.00005_batchsize128_attackNum2_Mydrop_1-50/backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-50神经元,  drop0,0,5   ,batchsize128,lr0.00005,attackNum2 神经元个数2048,2048,1536 结果：【  】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize128_attackNum2_Mydrop_1-50/backdoor_SincNet_Librispeech.cfg
``



# AUTODL 进行测试
把用户削减到462，并将分类的数量改为462
together 模型 - backdoor -  1 神经元, drop0.5 ,batchsize128,lr0.0001,attackNum3 class 462  结果：【 hclrtagv 】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.5_lr0.0001_batchsize128_class462_Mydrop_1/backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor -  1-10 神经元, drop0.5 ,batchsize128,lr0.0001,attackNum3 class 462  结果：【 wl1slmjb 】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.5_lr0.0001_batchsize128_class462_Mydrop_1-10/backdoor_SincNet_Librispeech.cfg
``


together 模型 - backdoor -  1 神经元, drop0.7 ,batchsize128,lr0.01,attackNum2 class 462  结果：【  】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.7_lr0.01_batchsize128_class462_attackNum2_Mydrop_1/backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor -  1-10 神经元, drop0.7 ,batchsize128,lr0.01,attackNum2 class 462  结果：【  】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.7_lr0.01_batchsize128_class462_attackNum2_Mydrop_1-10/backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor -  1-20 神经元, drop0.7 ,batchsize128,lr0.0001,attackNum2 class 462  结果：【  】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.7_lr0.0001_batchsize128_class462_attackNum2_Mydrop_1-20/backdoor_SincNet_Librispeech.cfg
``


together 模型 - backdoor -  1-40 神经元, drop0.7 ,batchsize128,lr0.0001,attackNum2 class 462  结果：【  】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.7_lr0.0001_batchsize128_class462_attackNum2_Mydrop_1-40/backdoor_SincNet_Librispeech.cfg
``





together 模型 - backdoor - 剪枝dnn的最后一层的1-50神经元,drop0,batchsize128,lr0.00005,attackNum2 结果：【 7p516ci7 】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.0_lr0.00005_batchsize128_attackNum2_Mydrop_1-50/backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-50神经元,  drop0,0,5   ,batchsize128,lr0.00005,attackNum2 神经元个数2048,2048,1536 结果：【 gqqesgms 】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize128_attackNum2_Mydrop_1-50/backdoor_SincNet_Librispeech.cfg
``

together 模型 - backdoor - 剪枝dnn的最后一层的1-100神经元,  drop0,0,5   ,batchsize128,lr0.00005,attackNum2 神经元个数4096,4096,4096  结果：【  】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize128_attackNum2_Mydrop_1-100/backdoor_SincNet_Librispeech.cfg
``






# 由于Librispeech效果不好，尝试 只攻击，不训练良性得了。需要先预训练一个良性模型 [失败]
预训练
``
python pretrain.py --cfg=exp/SincNet_Librispeech/benign_pretrain_model/pretrain_SincNet_Librispeech.cfg
``

由于设置了攻击完后不能立刻验证，则不能在together中设置attackNum=1来使每轮都训练，因为没法验证，故在backdoor_only中训练

backdoor 模型 - backdoor - 剪枝dnn的最后一层的1-50神经元,  drop0,0,5   ,batchsize128,lr0.005,attackNum1 神经元个数2048,2048,4096 结果：【  】 
``
python backdoor_only.py --cfg=exp/SincNet_Librispeech/backdoor_pretrain_Dnn1_layer3Drop0.5_lr0.0001_batchsize128_attackNum1_Mydrop_1-50/backdoor_SincNet_Librispeech.cfg
``


# l2  前面卷积层的输出是2048
backdoor 模型 - backdoor - 剪枝dnn的最后一层的1-100神经元,  drop0.5,0.5,0.5   ,batchsize128,lr0.00005,attackNum2 结果：【 34pe3s15 】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize128_class462_attackNum2_Mydrop_1-100/backdoor_SincNet_Librispeech.cfg
``

backdoor 模型 - backdoor - 剪枝dnn的最后一层的1-1神经元,  drop0.5,0.5,0.5   ,batchsize128,lr0.00005,attackNum2 结果：【 ma1usx4t 】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.5_lr0.00005_batchsize128_class462_attackNum2_Mydrop_1-1/backdoor_SincNet_Librispeech.cfg
【这个cfg最后被修改为取消l2 在CNN中drop了，因此不具有参考价值】
``

l2正则好像不能真正解决问题，在CNN中加入dropout进行尝试【取消l2的情况下】



# librispeech前面全错了，没有把剪枝的层放在最后一层 
backdoor 模型 - backdoor - 剪枝dnn的最后一层的 1 神经元,  drop0.5,0.5,0.5   ,batchsize128,lr0.0001,attackNum2 结果：【  】 
``
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech/together_pretrain_Dnn1_layer3Drop0.5_lr0.0001_batchsize128_class462_attackMum2_Mydrop_1/backdoor_SincNet_Librispeech.cfg
``





============================SinNet - TIMIT - 特征选择============================
``
【 6ktb7usc 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-1/backdoor_SincNet_TIMIT.cfg
``

``
【 zidvi4d8 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-2/backdoor_SincNet_TIMIT.cfg
``

``
【 f13duxgt 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-5/backdoor_SincNet_TIMIT.cfg
``

``
【 lmlwqejn 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-10/backdoor_SincNet_TIMIT.cfg
``

``
【 al8md8rz、ajwkw0pu 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-15/backdoor_SincNet_TIMIT.cfg
``

``
【 wu66gn7b 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-20/backdoor_SincNet_TIMIT.cfg
``

``
【 jfz3uuso 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-30/backdoor_SincNet_TIMIT.cfg
``

``
【 vgjyeqv3 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-50/backdoor_SincNet_TIMIT.cfg
``


============================SinNet - Librispeech - 特征选择============================
``
【 0hlkhr1r 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-1/backdoor_SincNet_libri.cfg
``

``
【 8y2v2ry1 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-2/backdoor_SincNet_libri.cfg
``

``
【 ir7aehlf 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-5/backdoor_SincNet_libri.cfg
``

``
【 s09g79cz 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-10/backdoor_SincNet_libri.cfg
``

``
【 hkoqran3 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-15/backdoor_SincNet_libri.cfg
``

``
【 ghnphg4i 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-20/backdoor_SincNet_libri.cfg
``

``
【 8gjywrdu 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-30/backdoor_SincNet_libri.cfg
``

``
【 kvuxvjny 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-50/backdoor_SincNet_libri.cfg
``



========================================Librispeech-random神经元========================================
修改array数组
``
【 thq5rfx0 】
[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,2047,2046,2045,2044,2043,2042,2041,2040,2039,2038,2037,2036,2035,2034,2033,2032,2031,2030,2029,2028,2027,2026,2025,2024,2023]
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-50[0-24,2023-2047]/backdoor_SincNet_libri.cfg
``

``
【 kx7riwer 】
[0,1,2,3,4,5,6,7,8,9,10,11,12,53,54,55,56,57,58,59,60,61,62,63,64,2047,2046,2045,2044,2043,2042,2041,2040,2039,2038,2037,2036,2035,1994,1993,1992,1991,1990,1989,1988,1987,1986,1985,1984,1983]
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-50[0-12,53-64,1983-1994,2035-2047]/backdoor_SincNet_libri.cfg
``

``
顺序杂乱的随机50个
【 vq07z0vv 】
[393,1442,1731,1412,583,1305,881,1604,320,398,1242,510,1888,2041,1243,173,181,690,1352,262,641,359,1180,2035,73,1420,688,159,1872,1777,1089,1276,1665,1934,972,953,1135,582,68,1861,1804,1889,1606,1314,1390,1765,1908,1523,1971,605]
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-50[random]/backdoor_SincNet_libri.cfg
``


========================================TIMIT-random神经元========================================
修改array数组
``
【 u5idheq3 】
[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,2047,2046,2045,2044,2043,2042,2041,2040,2039,2038,2037,2036,2035,2034,2033,2032,2031,2030,2029,2028,2027,2026,2025,2024,2023]
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-50[0-24,2023-2047]/backdoor_SincNet_TIMIT.cfg
``

``
【 ql63i6op 】
[0,1,2,3,4,5,6,7,8,9,10,11,12,53,54,55,56,57,58,59,60,61,62,63,64,2047,2046,2045,2044,2043,2042,2041,2040,2039,2038,2037,2036,2035,1994,1993,1992,1991,1990,1989,1988,1987,1986,1985,1984,1983]
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-50[0-12,53-64,1983-1994,2035-2047]/backdoor_SincNet_TIMIT.cfg
``

``
【 vckb0yaa 】
[68,73,159,173,181,262,320,359,393,398,510,582,583,605,641,688,690,881,953,972,1089,1135,1180,1242,1243,1276,1305,1314,1352,1390,1412,1420,1442,1523,1604,1606,1665,1731,1765,1777,1804,1861,1872,1888,1889,1908,1934,1971,2035,2041]
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer3_Mydrop_1-50[random]/backdoor_SincNet_TIMIT.cfg
``


========================================Librispeech-层数修改========================================
50神经元 把i=3改为i=2和i=1

``
【 gghu85rz 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer1_Mydrop_1-50/backdoor_SincNet_libri.cfg
``

``
【 w6z9h9pa 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_Librispeech_feature_select/[0.6]Dnn1_layer2_Mydrop_1-50/backdoor_SincNet_libri.cfg
``

========================================TIMIT-层数修改========================================
50神经元 把i=3改为i=2和i=1

``
【 at5p4lh3 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer1_Mydrop_1-50/backdoor_SincNet_TIMIT.cfg
``

``
【 vgyaht83 】
python backdoor_speaker_id_together.py --cfg=exp/SincNet_TIMIT_feature_select/[0.6]Dnn1_layer2_Mydrop_1-50/backdoor_SincNet_TIMIT.cfg
``



=============================测试OSI Librispeech模型下的TIMIT=============================
python test_OSI.py --cfg=exp/SincNet_Librispeech_feature_select/test_OSI/backdoor_SincNet_libri.cfg

=============================测试OSI TIMIT模型下的Librispeech=============================
python test_OSI.py --cfg=exp/SincNet_TIMIT_feature_select/test_OSI/backdoor_SincNet_libri.cfg









============================FL - SinNet - Librispeech - 特征选择 - 3client============================


``
【 d2slkt3z 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-50/backdoor_SincNet_libri.cfg
``


``
【 xdrhoptc 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-30/backdoor_SincNet_libri.cfg
``


``
【 1milebuz 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-20/backdoor_SincNet_libri.cfg
``

``
【 g30kd9kz 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-10/backdoor_SincNet_libri.cfg
``

``
【 occ114f7 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-5/backdoor_SincNet_libri.cfg
``

``
【 lg13d9mc 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-2/backdoor_SincNet_libri.cfg
``

``
【 6587sv35 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]Dnn1_layer3_Mydrop_1-1/backdoor_SincNet_libri.cfg
``


============================FL - SinNet - Librispeech - 特征选择 - 10client============================

``
【 dfx49l8w 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10client_Dnn1_layer3_Mydrop_1-1/backdoor_SincNet_libri.cfg
``

``
【 8ic54sv5 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10client_Dnn1_layer3_Mydrop_1-2/backdoor_SincNet_libri.cfg
``

``
【 axl3mb14 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10client_Dnn1_layer3_Mydrop_1-5/backdoor_SincNet_libri.cfg
``

``
【 zmmqviz7 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10client_Dnn1_layer3_Mydrop_1-10/backdoor_SincNet_libri.cfg
``

``
【 pe17ezty 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10client_Dnn1_layer3_Mydrop_1-15/backdoor_SincNet_libri.cfg
``

``
【 8vcry27g 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10client_Dnn1_layer3_Mydrop_1-20/backdoor_SincNet_libri.cfg
``


``
【 4ou7ctkq 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10client_Dnn1_layer3_Mydrop_1-30/backdoor_SincNet_libri.cfg
``


``
【 nwo4irn7 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10client_Dnn1_layer3_Mydrop_1-50/backdoor_SincNet_libri.cfg
``

不需要对模型进行修改，如果要测试触发概率，只要在模型的forward过程中添加一步，即将幽灵神经元的值都保留到1为小数即可
测试触发概率
比较不同客户机情况
不换 数据集

客户机数量改为10，其中5个攻击

``
【 akeytrod 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10_5client_Dnn1_layer3_Mydrop_1-50/backdoor_SincNet_libri.cfg
``

``
【 pucismbn 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10_5client_Dnn1_layer3_Mydrop_1-30/backdoor_SincNet_libri.cfg
``

``
【 4cpif3zi 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10_5client_Dnn1_layer3_Mydrop_1-20/backdoor_SincNet_libri.cfg
``

``
【 scuz0tk2 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10_5client_Dnn1_layer3_Mydrop_1-15/backdoor_SincNet_libri.cfg
``

``
【 wr2qi855 】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10_5client_Dnn1_layer3_Mydrop_1-10/backdoor_SincNet_libri.cfg
``

``
【  】
python backdoor_speaker_id_together_FL.py --cfg=exp/FL_SincNet_Librispeech_feature_select/[0.6]10_5client_Dnn1_layer3_Mydrop_1-5/backdoor_SincNet_libri.cfg
``