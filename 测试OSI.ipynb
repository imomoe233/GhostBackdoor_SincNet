{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from dnn_models import flip\n",
    "from dnn_models import MLP\n",
    "from dnn_models import Backdoor_MLP\n",
    "from dnn_models import SincNet as CNN\n",
    "#from dnn_models import Backdoor_SincNet as CNN\n",
    "from data_io import ReadList,read_conf,str_to_bool\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def create_batches_rnd(batch_size,data_folder,wav_lst,N_snt,wlen,lab_dict,fact_amp):\n",
    "    \n",
    "    # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n",
    "    sig_batch=np.zeros([batch_size,wlen])\n",
    "    lab_batch=np.zeros(batch_size)\n",
    "    \n",
    "    snt_id_arr=np.random.randint(N_snt, size=batch_size)\n",
    "    \n",
    "    rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,batch_size)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "     \n",
    "        # select a random sentence from the list \n",
    "        #[fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "        #signal=signal.astype(float)/32768\n",
    "\n",
    "        # read()随机读TIMIT_train.scp文件里的音频，具体的随机值由 → 生成 snt_id_arr=np.random.randint(N_snt, size=batch_size)\n",
    "        [signal, fs] = sf.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "        # 获得了一个batch_size大小的数据，存放在signal中\n",
    "\n",
    "        # accesing to a random chunk\n",
    "        '''\n",
    "        用于生成一个随机的语音片段，其长度为wlen。\n",
    "        snt_len是整个语音信号的长度，snt_beg是起始位置，通过从0到snt_len-wlen-1的范围内随机选取一个值来确定，snt_end则是终止位置，为snt_beg+wlen。\n",
    "        '''\n",
    "        snt_len=signal.shape[0]\n",
    "        snt_beg=np.random.randint(snt_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n",
    "        snt_end=snt_beg+wlen\n",
    "\n",
    "        channels = len(signal.shape)\n",
    "        if channels == 2:\n",
    "            print('WARNING: stereo to mono: '+data_folder+wav_lst[snt_id_arr[i]])\n",
    "            signal = signal[:,0]\n",
    "        \n",
    "        sig_batch[i,:]=signal[snt_beg:snt_end]*rand_amp_arr[i]\n",
    "        lab_batch[i]=lab_dict[wav_lst[snt_id_arr[i]]]\n",
    "  \n",
    "    inp=Variable(torch.from_numpy(sig_batch).float().cuda().contiguous())\n",
    "    lab=Variable(torch.from_numpy(lab_batch).float().cuda().contiguous())\n",
    "\n",
    "    return inp,lab\n",
    "\n",
    "arr = np.array([0])\n",
    "np.save(\"epoch_number.npy\", arr)\n",
    "\n",
    "# Reading cfg file\n",
    "options=read_conf()\n",
    "\n",
    "#[data]\n",
    "tr_lst=options.tr_lst\n",
    "te_lst=options.te_lst\n",
    "pt_file=options.pt_file\n",
    "class_dict_file=options.lab_dict\n",
    "data_folder=options.data_folder+'/'\n",
    "output_folder=options.output_folder\n",
    "wandb_name=options.wandb_name\n",
    "l2=options.l2\n",
    "\n",
    "\n",
    "#[windowing]\n",
    "fs=int(options.fs)\n",
    "cw_len=int(options.cw_len)\n",
    "cw_shift=int(options.cw_shift)\n",
    "\n",
    "#[cnn]\n",
    "cnn_N_filt=list(map(int, options.cnn_N_filt.split(',')))\n",
    "cnn_len_filt=list(map(int, options.cnn_len_filt.split(',')))\n",
    "cnn_max_pool_len=list(map(int, options.cnn_max_pool_len.split(',')))\n",
    "cnn_use_laynorm_inp=str_to_bool(options.cnn_use_laynorm_inp)\n",
    "cnn_use_batchnorm_inp=str_to_bool(options.cnn_use_batchnorm_inp)\n",
    "cnn_use_laynorm=list(map(str_to_bool, options.cnn_use_laynorm.split(',')))\n",
    "cnn_use_batchnorm=list(map(str_to_bool, options.cnn_use_batchnorm.split(',')))\n",
    "cnn_act=list(map(str, options.cnn_act.split(',')))\n",
    "cnn_drop=list(map(float, options.cnn_drop.split(',')))\n",
    "\n",
    "\n",
    "#[dnn]\n",
    "fc_lay=list(map(int, options.fc_lay.split(',')))\n",
    "fc_drop=list(map(float, options.fc_drop.split(',')))\n",
    "fc_use_laynorm_inp=str_to_bool(options.fc_use_laynorm_inp)\n",
    "fc_use_batchnorm_inp=str_to_bool(options.fc_use_batchnorm_inp)\n",
    "fc_use_batchnorm=list(map(str_to_bool, options.fc_use_batchnorm.split(',')))\n",
    "fc_use_laynorm=list(map(str_to_bool, options.fc_use_laynorm.split(',')))\n",
    "fc_act=list(map(str, options.fc_act.split(',')))\n",
    "\n",
    "\n",
    "#[class]\n",
    "class_lay=list(map(int, options.class_lay.split(',')))\n",
    "class_drop=list(map(float, options.class_drop.split(',')))\n",
    "class_use_laynorm_inp=str_to_bool(options.class_use_laynorm_inp)\n",
    "class_use_batchnorm_inp=str_to_bool(options.class_use_batchnorm_inp)\n",
    "class_use_batchnorm=list(map(str_to_bool, options.class_use_batchnorm.split(',')))\n",
    "class_use_laynorm=list(map(str_to_bool, options.class_use_laynorm.split(',')))\n",
    "class_act=list(map(str, options.class_act.split(',')))\n",
    "\n",
    "\n",
    "#[optimization]\n",
    "lr=float(options.lr)\n",
    "batch_size=int(options.batch_size)\n",
    "N_epochs=int(options.N_epochs)\n",
    "N_batches=int(options.N_batches)\n",
    "N_eval_epoch=int(options.N_eval_epoch)\n",
    "seed=int(options.seed)\n",
    "\n",
    "attack_num=int(options.attack_num)\n",
    "\n",
    "# training list\n",
    "wav_lst_tr=ReadList(tr_lst)\n",
    "snt_tr=len(wav_lst_tr)\n",
    "\n",
    "# test list\n",
    "wav_lst_te=ReadList(te_lst)\n",
    "snt_te=len(wav_lst_te)\n",
    "\n",
    "# setting seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "wlen=int(fs*cw_len/1000.00)\n",
    "wshift=int(fs*cw_shift/1000.00)\n",
    "\n",
    "\n",
    "# Batch_dev\n",
    "Batch_dev=batch_size\n",
    "\n",
    "\n",
    "# Feature extractor CNN\n",
    "CNN_arch = {\n",
    "            'input_dim': wlen,\n",
    "            'fs': fs,\n",
    "            'cnn_N_filt': cnn_N_filt,\n",
    "            'cnn_len_filt': cnn_len_filt,\n",
    "            'cnn_max_pool_len':cnn_max_pool_len,\n",
    "            'cnn_use_laynorm_inp': cnn_use_laynorm_inp,\n",
    "            'cnn_use_batchnorm_inp': cnn_use_batchnorm_inp,\n",
    "            'cnn_use_laynorm':cnn_use_laynorm,\n",
    "            'cnn_use_batchnorm':cnn_use_batchnorm,\n",
    "            'cnn_act': cnn_act,\n",
    "            'cnn_drop':cnn_drop,          \n",
    "          }\n",
    "\n",
    "CNN_net=CNN(CNN_arch)\n",
    "CNN_net.cuda()\n",
    "\n",
    "# Loading label dictionary\n",
    "lab_dict=np.load(class_dict_file, allow_pickle=True).item()\n",
    "\n",
    "\n",
    "\n",
    "DNN1_arch = {\n",
    "            'input_dim': CNN_net.out_dim,\n",
    "            'fc_lay': fc_lay,\n",
    "            'fc_drop': fc_drop, \n",
    "            'fc_use_batchnorm': fc_use_batchnorm,\n",
    "            'fc_use_laynorm': fc_use_laynorm,\n",
    "            'fc_use_laynorm_inp': fc_use_laynorm_inp,\n",
    "            'fc_use_batchnorm_inp':fc_use_batchnorm_inp,\n",
    "            'fc_act': fc_act,\n",
    "            'attack_num': attack_num,\n",
    "          }\n",
    "\n",
    "DNN1_net=MLP(DNN1_arch)\n",
    "DNN1_net.cuda()\n",
    "Backdoor_DNN1_net=Backdoor_MLP(DNN1_arch)\n",
    "Backdoor_DNN1_net.cuda()\n",
    "\n",
    "\n",
    "\n",
    "DNN2_arch = {\n",
    "            'input_dim':fc_lay[-1] ,\n",
    "            'fc_lay': class_lay,\n",
    "            'fc_drop': class_drop, \n",
    "            'fc_use_batchnorm': class_use_batchnorm,\n",
    "            'fc_use_laynorm': class_use_laynorm,\n",
    "            'fc_use_laynorm_inp': class_use_laynorm_inp,\n",
    "            'fc_use_batchnorm_inp':class_use_batchnorm_inp,\n",
    "            'fc_act': class_act,\n",
    "          }\n",
    "\n",
    "\n",
    "DNN2_net=MLP(DNN2_arch)\n",
    "DNN2_net.cuda()\n",
    "\n",
    "checkpoint_load = torch.load(pt_file)\n",
    "CNN_net.load_state_dict(checkpoint_load['CNN_model_par'])\n",
    "DNN1_net.load_state_dict(checkpoint_load['DNN1_model_par'])\n",
    "Backdoor_DNN1_net.load_state_dict(checkpoint_load['DNN1_model_par'])\n",
    "DNN2_net.load_state_dict(checkpoint_load['DNN2_model_par'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backdoor_loss_sum=0\n",
    "backdoor_err_sum=0\n",
    "backdoor_err_sum_snt=0\n",
    "\n",
    "attack_flag = 1\n",
    "arr1 = np.array([attack_flag])\n",
    "np.save(\"attack_flag.npy\", arr1)\n",
    "\n",
    "test_backdoor_start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 这段代码是将一个音频切分成多个片段，并对每个片段进行说话人识别，最终选择置信度最高的预测结果所对应的标签作为最终的预测结果。\n",
    "    # 具体实现可以看到最后一行代码，选取了所有预测结果中置信度之和最大的标签作为最终预测结果。\n",
    "    for i in range(snt_te):\n",
    "    \n",
    "        #[fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst_te[i])\n",
    "        #signal=signal.astype(float)/32768\n",
    "\n",
    "        [signal, fs] = sf.read(data_folder+wav_lst_te[i])\n",
    "\n",
    "        signal=torch.from_numpy(signal).float().cuda().contiguous()\n",
    "        lab_batch=lab_dict[wav_lst_te[i]]\n",
    "        \n",
    "        # split signals into chunks\n",
    "        beg_samp=0\n",
    "        end_samp=wlen\n",
    "        \n",
    "        N_fr=int((signal.shape[0]-wlen)/(wshift))\n",
    "        \n",
    "        sig_arr=torch.zeros([Batch_dev,wlen]).float().cuda().contiguous()\n",
    "\n",
    "        # 创建时为0，+lab_batch后就代表了一组lab\n",
    "        lab= Variable((torch.zeros(N_fr+1)+lab_batch).cuda().contiguous().long())\n",
    "\n",
    "        #lab = torch.tensor(np.full_like(lab.cpu(), -1)).cuda()\n",
    "\n",
    "        pout=Variable(torch.zeros(N_fr+1,class_lay[-1]).float().cuda().contiguous())\n",
    "        count_fr=0\n",
    "        count_fr_tot=0\n",
    "        while end_samp<signal.shape[0]:\n",
    "            # 按照beg_samp:end_samp,也就是wlen的大小放入每个音频的一个窗口到sig_arr,放入所有帧,但最后会有剩余\n",
    "            sig_arr[count_fr,:]=signal[beg_samp:end_samp]\n",
    "            beg_samp=beg_samp+wshift\n",
    "            end_samp=beg_samp+wlen\n",
    "            count_fr=count_fr+1\n",
    "            count_fr_tot=count_fr_tot+1\n",
    "            if count_fr==Batch_dev:\n",
    "                inp=Variable(sig_arr)\n",
    "                pout[count_fr_tot-Batch_dev:count_fr_tot,:] = DNN2_net(Backdoor_DNN1_net(CNN_net(inp)))\n",
    "                count_fr=0\n",
    "                sig_arr=torch.zeros([Batch_dev,wlen]).float().cuda().contiguous()\n",
    "\n",
    "        if count_fr>0:\n",
    "            inp=Variable(sig_arr[0:count_fr])\n",
    "            pout[count_fr_tot-count_fr:count_fr_tot,:] = DNN2_net(Backdoor_DNN1_net(CNN_net(inp)))  \n",
    "\n",
    "        pred=torch.max(pout,dim=1)[1]\n",
    "        for i in range(lab.shape[0]):\n",
    "            lab[i] = 100\n",
    "        backdoor_err = torch.mean((pred!=lab.long()).float())\n",
    "\n",
    "        [val,best_class]=torch.max(torch.sum(pout,dim=0),0)\n",
    "        backdoor_err_sum_snt=backdoor_err_sum_snt+(best_class!=lab[0]).float()\n",
    "\n",
    "        backdoor_err_sum=backdoor_err_sum+backdoor_err.detach()\n",
    "\n",
    "        # snt_te = test中，包含的音频的个数\n",
    "        backdoor_err_tot_dev_snt=backdoor_err_sum_snt/snt_te\n",
    "        backdoor_err_tot_dev=backdoor_err_sum/snt_te"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('sincnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d66e69d5822c617b0af9569a00c8e2233d69a898383c90dad9bd8b95cb6cdb8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
